{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a98624a",
   "metadata": {},
   "source": [
    "# Recall Machine Learning Linear Regression\n",
    "\n",
    "At the end of this Lesson the studen will remember the main steps to train a model:\n",
    "\n",
    " - Split dataset in train and test subsets\n",
    " - Standardize continuous varuables\n",
    " - Transform categorical variables to dummy\n",
    " - Train linear regression models\n",
    " - Train classification models\n",
    " - Interpret the error and accuracy metrics to validate the built models\n",
    "\n",
    "**You have two exercises at the end of the notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7589307d",
   "metadata": {},
   "source": [
    "### Import data and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23ad14c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2e209b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Length1</th>\n",
       "      <th>Length2</th>\n",
       "      <th>Length3</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bream</td>\n",
       "      <td>242.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>25.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.5200</td>\n",
       "      <td>4.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bream</td>\n",
       "      <td>290.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>31.2</td>\n",
       "      <td>12.4800</td>\n",
       "      <td>4.3056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bream</td>\n",
       "      <td>340.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>26.5</td>\n",
       "      <td>31.1</td>\n",
       "      <td>12.3778</td>\n",
       "      <td>4.6961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bream</td>\n",
       "      <td>363.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>33.5</td>\n",
       "      <td>12.7300</td>\n",
       "      <td>4.4555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bream</td>\n",
       "      <td>430.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.4440</td>\n",
       "      <td>5.1340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Smelt</td>\n",
       "      <td>12.2</td>\n",
       "      <td>11.5</td>\n",
       "      <td>12.2</td>\n",
       "      <td>13.4</td>\n",
       "      <td>2.0904</td>\n",
       "      <td>1.3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Smelt</td>\n",
       "      <td>13.4</td>\n",
       "      <td>11.7</td>\n",
       "      <td>12.4</td>\n",
       "      <td>13.5</td>\n",
       "      <td>2.4300</td>\n",
       "      <td>1.2690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Smelt</td>\n",
       "      <td>12.2</td>\n",
       "      <td>12.1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>2.2770</td>\n",
       "      <td>1.2558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Smelt</td>\n",
       "      <td>19.7</td>\n",
       "      <td>13.2</td>\n",
       "      <td>14.3</td>\n",
       "      <td>15.2</td>\n",
       "      <td>2.8728</td>\n",
       "      <td>2.0672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Smelt</td>\n",
       "      <td>19.9</td>\n",
       "      <td>13.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>2.9322</td>\n",
       "      <td>1.8792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Species  Weight  Length1  Length2  Length3   Height   Width\n",
       "0     Bream   242.0     23.2     25.4     30.0  11.5200  4.0200\n",
       "1     Bream   290.0     24.0     26.3     31.2  12.4800  4.3056\n",
       "2     Bream   340.0     23.9     26.5     31.1  12.3778  4.6961\n",
       "3     Bream   363.0     26.3     29.0     33.5  12.7300  4.4555\n",
       "4     Bream   430.0     26.5     29.0     34.0  12.4440  5.1340\n",
       "..      ...     ...      ...      ...      ...      ...     ...\n",
       "154   Smelt    12.2     11.5     12.2     13.4   2.0904  1.3936\n",
       "155   Smelt    13.4     11.7     12.4     13.5   2.4300  1.2690\n",
       "156   Smelt    12.2     12.1     13.0     13.8   2.2770  1.2558\n",
       "157   Smelt    19.7     13.2     14.3     15.2   2.8728  2.0672\n",
       "158   Smelt    19.9     13.8     15.0     16.2   2.9322  1.8792\n",
       "\n",
       "[159 rows x 7 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Fish.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b223673d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159 entries, 0 to 158\n",
      "Data columns (total 7 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   Species  159 non-null    object \n",
      " 1   Weight   159 non-null    float64\n",
      " 2   Length1  159 non-null    float64\n",
      " 3   Length2  159 non-null    float64\n",
      " 4   Length3  159 non-null    float64\n",
      " 5   Height   159 non-null    float64\n",
      " 6   Width    159 non-null    float64\n",
      "dtypes: float64(6), object(1)\n",
      "memory usage: 8.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc62392a",
   "metadata": {},
   "source": [
    "### Species variable treatment\n",
    "\n",
    "Species is a categorical variable, hence we need to transform it to dummies before inserting in the model\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a419c133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perch        56\n",
       "Bream        35\n",
       "Roach        20\n",
       "Pike         17\n",
       "Smelt        14\n",
       "Parkki       11\n",
       "Whitefish     6\n",
       "Name: Species, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Species.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0614800",
   "metadata": {},
   "source": [
    "Firstly, let's reduce the categories to Perch, Bream and Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e973527c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Length1</th>\n",
       "      <th>Length2</th>\n",
       "      <th>Length3</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "      <th>fish_species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bream</td>\n",
       "      <td>242.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>25.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.5200</td>\n",
       "      <td>4.0200</td>\n",
       "      <td>Bream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bream</td>\n",
       "      <td>290.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>31.2</td>\n",
       "      <td>12.4800</td>\n",
       "      <td>4.3056</td>\n",
       "      <td>Bream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bream</td>\n",
       "      <td>340.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>26.5</td>\n",
       "      <td>31.1</td>\n",
       "      <td>12.3778</td>\n",
       "      <td>4.6961</td>\n",
       "      <td>Bream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bream</td>\n",
       "      <td>363.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>33.5</td>\n",
       "      <td>12.7300</td>\n",
       "      <td>4.4555</td>\n",
       "      <td>Bream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bream</td>\n",
       "      <td>430.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.4440</td>\n",
       "      <td>5.1340</td>\n",
       "      <td>Bream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Smelt</td>\n",
       "      <td>12.2</td>\n",
       "      <td>11.5</td>\n",
       "      <td>12.2</td>\n",
       "      <td>13.4</td>\n",
       "      <td>2.0904</td>\n",
       "      <td>1.3936</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Smelt</td>\n",
       "      <td>13.4</td>\n",
       "      <td>11.7</td>\n",
       "      <td>12.4</td>\n",
       "      <td>13.5</td>\n",
       "      <td>2.4300</td>\n",
       "      <td>1.2690</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Smelt</td>\n",
       "      <td>12.2</td>\n",
       "      <td>12.1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>2.2770</td>\n",
       "      <td>1.2558</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Smelt</td>\n",
       "      <td>19.7</td>\n",
       "      <td>13.2</td>\n",
       "      <td>14.3</td>\n",
       "      <td>15.2</td>\n",
       "      <td>2.8728</td>\n",
       "      <td>2.0672</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Smelt</td>\n",
       "      <td>19.9</td>\n",
       "      <td>13.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>2.9322</td>\n",
       "      <td>1.8792</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Species  Weight  Length1  Length2  Length3   Height   Width fish_species\n",
       "0     Bream   242.0     23.2     25.4     30.0  11.5200  4.0200        Bream\n",
       "1     Bream   290.0     24.0     26.3     31.2  12.4800  4.3056        Bream\n",
       "2     Bream   340.0     23.9     26.5     31.1  12.3778  4.6961        Bream\n",
       "3     Bream   363.0     26.3     29.0     33.5  12.7300  4.4555        Bream\n",
       "4     Bream   430.0     26.5     29.0     34.0  12.4440  5.1340        Bream\n",
       "..      ...     ...      ...      ...      ...      ...     ...          ...\n",
       "154   Smelt    12.2     11.5     12.2     13.4   2.0904  1.3936       Others\n",
       "155   Smelt    13.4     11.7     12.4     13.5   2.4300  1.2690       Others\n",
       "156   Smelt    12.2     12.1     13.0     13.8   2.2770  1.2558       Others\n",
       "157   Smelt    19.7     13.2     14.3     15.2   2.8728  2.0672       Others\n",
       "158   Smelt    19.9     13.8     15.0     16.2   2.9322  1.8792       Others\n",
       "\n",
       "[159 rows x 8 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fish_species(x):\n",
    "    if x == 'Perch':\n",
    "        return 'Perch'\n",
    "    elif x == 'Bream':\n",
    "        return 'Bream'\n",
    "    else:\n",
    "        return 'Others'\n",
    "\n",
    "df['fish_species'] = df['Species'].apply(fish_species)    \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a42172",
   "metadata": {},
   "source": [
    "### Get dummies\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html\n",
    "\n",
    "https://stats.stackexchange.com/questions/350492/why-do-we-create-dummy-variables\n",
    "\n",
    "https://towardsdatascience.com/what-are-dummy-variables-and-how-to-use-them-in-a-regression-model-ee43640d573e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3a7ff6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dum = pd.get_dummies(df.fish_species)\n",
    "df = df.merge(df_dum, right_index = True, left_index = True, how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00222b8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Weight', 'Length1', 'Length2', 'Length3', 'Height', 'Width', 'Bream',\n",
       "       'Others', 'Perch'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['Species','fish_species'], axis = 1, inplace = True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c2a911",
   "metadata": {},
   "source": [
    "### Train test split\n",
    "\n",
    "It is mandatory to randomly divide the dataset into two. One for training the model and the test split for validate it.\n",
    "\n",
    "If error metrics are low with the test split means that our model is robust\n",
    "\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02e7faad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_train, fish_test = train_test_split(df, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce85406a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127, 9)\n",
      "(32, 9)\n"
     ]
    }
   ],
   "source": [
    "print(fish_train.shape)\n",
    "print(fish_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb0b22a",
   "metadata": {},
   "source": [
    "### Standardize the numerical variables\n",
    "\n",
    "Sometimes numerical variables in our dataset have very different scales, taht's to have very different values between one column and other. That can harm model accuracy.\n",
    "\n",
    "For solve this situation, we standardize, that's to put every continuous variable centered in 0 and with standard deviation 1\n",
    "\n",
    "We **first** standardize the training set, then the test set with the training set parameters\n",
    "\n",
    "We do not standardize the target variable\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler\n",
    "\n",
    "\n",
    "https://www.askpython.com/python/examples/standardize-data-in-python#:~:text=Ways%20to%20Standardize%20Data%20in%20Python%201%201.,load_iris%20...%202%202.%20Using%20StandardScaler%20%28%29%20function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556f9391",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale= StandardScaler()\n",
    "\n",
    "variables_sc = ['duration_ms', 'loudness', 'tempo']\n",
    "\n",
    "scale_fit = scale.fit(X_train1[variables_sc])\n",
    "\n",
    "X_train_sc = pd.DataFrame(scale.transform(X_train1[variables_sc]), columns = variables_sc)\n",
    "\n",
    "X_test_sc = pd.DataFrame(scale.transform(X_test1[variables_sc]), columns = variables_sc)\n",
    "\n",
    "X_train_sc.shape\n",
    "\n",
    "X_train1.drop(variables_sc, axis = 1, inplace = True)\n",
    "X_train1 = X_train1.reset_index(drop = True)\n",
    "y_train1 = y_train1.reset_index(drop=True)\n",
    "X_train = pd.concat([X_train1, X_train_sc], axis = 1)\n",
    "\n",
    "X_test1.drop(variables_sc, axis = 1, inplace = True)\n",
    "X_test1 = X_test1.reset_index(drop = True)\n",
    "y_test1 = y_test1.reset_index(drop=True)\n",
    "X_test = pd.concat([X_test1, X_test_sc], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d1580d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale= StandardScaler()\n",
    "variables_sc = ['Length1', 'Length2', 'Length3', 'Height', 'Width']\n",
    "\n",
    "X_train = fish_train[['Length1', 'Length2', 'Length3', 'Height', 'Width', 'Bream','Others', 'Perch']]\n",
    "y_train  = fish_train['Weight']\n",
    "\n",
    "X_test = fish_test[['Length1', 'Length2', 'Length3', 'Height', 'Width', 'Bream', 'Others', 'Perch']]\n",
    "y_test  = fish_test['Weight']\n",
    "\n",
    "\n",
    "scale_train = scale.fit(X_train[variables_sc])\n",
    "\n",
    "X_train_sc = pd.DataFrame(scale_train.transform(X_train[variables_sc]), columns = [variables_sc])\n",
    "X_train = X_train.drop(variables_sc, axis = 1) # , inplace = True\n",
    "X_train = X_train.reset_index(drop = True)\n",
    "X_train = pd.concat([X_train, X_train_sc], axis = 1)\n",
    "X_train.columns = ['Length1', 'Length2', 'Length3', 'Height', 'Width', 'Bream','Others', 'Perch']\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "X_test_sc = pd.DataFrame(scale_train.transform(X_test[variables_sc]), columns =[variables_sc])\n",
    "X_test = X_test.drop(variables_sc, axis = 1) # , inplace = True\n",
    "X_test = X_test.reset_index(drop = True)\n",
    "X_test = pd.concat([X_test, X_test_sc], axis = 1)\n",
    "X_test.columns = ['Length1', 'Length2', 'Length3', 'Height', 'Width', 'Bream','Others', 'Perch']\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3a411c",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "https://medium.com/swlh/interpreting-linear-regression-through-statsmodels-summary-4796d359035a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53e13378",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 Weight   R-squared:                       0.895\n",
      "Model:                            OLS   Adj. R-squared:                  0.889\n",
      "Method:                 Least Squares   F-statistic:                     144.5\n",
      "Date:                Sat, 23 Sep 2023   Prob (F-statistic):           4.55e-55\n",
      "Time:                        19:10:56   Log-Likelihood:                -774.25\n",
      "No. Observations:                 127   AIC:                             1564.\n",
      "Df Residuals:                     119   BIC:                             1587.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        304.3119     10.022     30.365      0.000     284.468     324.156\n",
      "Length1      278.1116     62.595      4.443      0.000     154.167     402.057\n",
      "Length2       72.4836     21.213      3.417      0.001      30.480     114.487\n",
      "Length3      -46.2833     46.741     -0.990      0.324    -138.834      46.268\n",
      "Height       598.9980    405.173      1.478      0.142    -203.286    1401.282\n",
      "Width        737.7313    560.932      1.315      0.191    -372.971    1848.434\n",
      "Bream      -1237.3795    350.647     -3.529      0.001   -1931.697    -543.062\n",
      "Others       107.2512     42.137      2.545      0.012      23.816     190.687\n",
      "Perch        111.4450     41.745      2.670      0.009      28.786     194.104\n",
      "==============================================================================\n",
      "Omnibus:                       33.011   Durbin-Watson:                   1.687\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               77.695\n",
      "Skew:                           1.024   Prob(JB):                     1.35e-17\n",
      "Kurtosis:                       6.239   Cond. No.                     5.33e+15\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is  2e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "X_train = sm.add_constant(X_train)\n",
    "result = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d33fde23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train['predict'] = result.predict(X_train)\n",
    "\n",
    "X_test = sm.add_constant(X_test)\n",
    "X_test['predict'] = result.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "216f039c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  79.48159685784069\n",
      "MSE:  11556.170674549498\n",
      "RMSE:  107.49963104378311\n",
      "MAPE:  6.033857813902521e-14\n",
      "R2:  0.8947146195772225\n"
     ]
    }
   ],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((sum(y_true) - sum(y_pred)) / sum(y_true))) * 100  \n",
    "\n",
    "print(\"MAE: \", metrics.mean_absolute_error(y_train, X_train['predict']))\n",
    "print(\"MSE: \", metrics.mean_squared_error(y_train, X_train['predict']))\n",
    "print(\"RMSE: \", np.sqrt(metrics.mean_squared_error(y_train, X_train['predict'])))\n",
    "print(\"MAPE: \", mean_absolute_percentage_error(y_train, X_train['predict']))\n",
    "print(\"R2: \", metrics.r2_score(y_train, X_train['predict']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e8b4c39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  99.17774652309299\n",
      "MSE:  26636.577496367645\n",
      "RMSE:  163.20716129008446\n",
      "MAPE:  3.1590670956093923\n",
      "R2:  0.8600657372046434\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE: \", metrics.mean_absolute_error(y_test, X_test['predict']))\n",
    "print(\"MSE: \", metrics.mean_squared_error(y_test, X_test['predict']))\n",
    "print(\"RMSE: \", np.sqrt(metrics.mean_squared_error(y_test, X_test['predict'])))\n",
    "print(\"MAPE: \", mean_absolute_percentage_error(y_test, X_test['predict']))\n",
    "print(\"R2: \", metrics.r2_score(y_test, X_test['predict']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbaee41",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Response the answers in 4-5 lines each, read the links you have along this document, or in the theory notebooks, or you can also search on the internet:\n",
    "\n",
    " - Which type of variables do we transform into dummies? Why do we do it?\n",
    "\n",
    "   We transform categorical variables into dummy variables to represent non-numeric data in mathematical models. This allows us to preserve the information of the original categories and avoid erroneous interpretations of ordinal relationships. The most common method is one-hot encoding, where each category becomes a binary column. Additionally, it's important to drop one category to prevent multicollinearity and the \"dummy variable trap.\"\n",
    "\n",
    " - Why is so important to divide our data into train and test datasets? Which is the purpose of doing it?\n",
    "\n",
    "    It is important to divide our data into train and test datasets to avoid overfitting. The purpose of doing it is to train the model with the train dataset and then test it with the test dataset to see if the model is robust.\n",
    "\n",
    " - Why do we standardize some varaiables? Which type of variables do we standardize?\n",
    "\n",
    "    We standardize some variables to avoid having variables with very different scales, which can harm model accuracy. We standardize continuous variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f23018",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Regarding the summary and the errors, Would you use this model to predict the weights of the fishes? Justify your answer. Comment the usefulness of the main indicators of the summary and the errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffa9cab",
   "metadata": {},
   "source": [
    "This model has a high R-squared and a significant F-statistic, indicating a strong relationship between predictors and fish weights. However, concerns about multicollinearity and non-normal residuals should be addressed before using it for predictions. Further validation and consideration of specific application needs are necessary.\n",
    "\n",
    "1. R-squared and Adj. R-squared:\n",
    "\n",
    "    -Usefulness: These metrics provide a measure of how well the independent variables explain the variation in the dependent variable. An R-squared of 0.895 indicates a strong relationship, suggesting that the model explains a significant portion of the variation in fish weights.\n",
    "\n",
    "2. F-statistic and P-value:\n",
    "\n",
    "    -Usefulness: The low p-value (4.55e-55) for the F-statistic suggests that the model is statistically significant as a whole.\n",
    "\n",
    "3. Coefficients and P-values for Individual Predictors:\n",
    "\n",
    "    -Usefulness: The coefficients and their associated p-values provide information about the strength and significance of the relationship between each predictor and the dependent variable.\n",
    "\n",
    "4. Omnibus and Jarque-Bera Tests:\n",
    "\n",
    "    -Usefulness: These tests check the assumptions of normality for the residuals.\n",
    "\n",
    "5. Durbin-Watson Statistic:\n",
    "\n",
    "    Usefulness: It tests for autocorrelation in the residuals.\n",
    "\n",
    "6. Cond. No. (Condition Number):\n",
    "\n",
    "    -Usefulness: It measures multicollinearity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
